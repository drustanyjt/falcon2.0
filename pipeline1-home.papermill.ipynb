{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecabb033",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [9]</a>'.</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88f00a03",
   "metadata": {
    "papermill": {
     "duration": 0.001763,
     "end_time": "2023-07-12T15:01:46.180271",
     "exception": false,
     "start_time": "2023-07-12T15:01:46.178508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d9e5f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T15:01:46.183919Z",
     "iopub.status.busy": "2023-07-12T15:01:46.183565Z",
     "iopub.status.idle": "2023-07-12T15:01:46.666857Z",
     "shell.execute_reply": "2023-07-12T15:01:46.666365Z"
    },
    "papermill": {
     "duration": 0.486101,
     "end_time": "2023-07-12T15:01:46.667683",
     "exception": false,
     "start_time": "2023-07-12T15:01:46.181582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pipeline import Falcon2Linker, SerialAnnotator, T5Converter\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c844b92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T15:01:46.671015Z",
     "iopub.status.busy": "2023-07-12T15:01:46.670673Z",
     "iopub.status.idle": "2023-07-12T15:01:46.673129Z",
     "shell.execute_reply": "2023-07-12T15:01:46.672688Z"
    },
    "papermill": {
     "duration": 0.005069,
     "end_time": "2023-07-12T15:01:46.673777",
     "exception": false,
     "start_time": "2023-07-12T15:01:46.668708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "linker = Falcon2Linker()\n",
    "annotator = SerialAnnotator()\n",
    "converter = T5Converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196f9756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T15:01:46.676285Z",
     "iopub.status.busy": "2023-07-12T15:01:46.676081Z",
     "iopub.status.idle": "2023-07-12T15:01:46.678095Z",
     "shell.execute_reply": "2023-07-12T15:01:46.677728Z"
    },
    "papermill": {
     "duration": 0.004155,
     "end_time": "2023-07-12T15:01:46.678878",
     "exception": false,
     "start_time": "2023-07-12T15:01:46.674723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "utterance = \"Who is the wife of Barack Obama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c4ae5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T15:01:46.681412Z",
     "iopub.status.busy": "2023-07-12T15:01:46.681210Z",
     "iopub.status.idle": "2023-07-12T15:01:55.486572Z",
     "shell.execute_reply": "2023-07-12T15:01:55.485122Z"
    },
    "papermill": {
     "duration": 8.808357,
     "end_time": "2023-07-12T15:01:55.488301",
     "exception": false,
     "start_time": "2023-07-12T15:01:46.679944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recieved utterance\n",
      "0 : ['Who is the wife of Barack Obama']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who is the wife of Barack Obama \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 1.024972677230835 \n",
      "SPARQL Avg Time per Qn: 1.024972677230835\n",
      "['Who is the wife of Barack Obama', [['<http://www.wikidata.org/entity/P26>', 'wife'], ['<http://www.wikidata.org/entity/P2848>', 'wife'], ['<http://www.wikidata.org/entity/P140>', 'wife'], ['<http://www.wikidata.org/entity/P451>', 'wife'], ['<http://www.wikidata.org/entity/P600>', 'wife']], [['<http://www.wikidata.org/entity/Q76>', 'Barack obama'], ['<http://www.wikidata.org/entity/Q649593>', 'Barack obama'], ['<http://www.wikidata.org/entity/Q4808526>', 'Barack obama'], ['<http://www.wikidata.org/entity/Q4858106>', 'Barack obama'], ['<http://www.wikidata.org/entity/Q643049>', 'Barack obama']], 0, 0, 0, 0]\n",
      "'Linked'\n",
      "{'ents': [{'id': 'Q76',\n",
      "           'prefix': 'wd:',\n",
      "           'uri': 'http://www.wikidata.org/entity/Q76'},\n",
      "          {'id': 'Q649593',\n",
      "           'prefix': 'wd:',\n",
      "           'uri': 'http://www.wikidata.org/entity/Q649593'},\n",
      "          {'id': 'Q4808526',\n",
      "           'prefix': 'wd:',\n",
      "           'uri': 'http://www.wikidata.org/entity/Q4808526'},\n",
      "          {'id': 'Q4858106',\n",
      "           'prefix': 'wd:',\n",
      "           'uri': 'http://www.wikidata.org/entity/Q4858106'},\n",
      "          {'id': 'Q643049',\n",
      "           'prefix': 'wd:',\n",
      "           'uri': 'http://www.wikidata.org/entity/Q643049'}],\n",
      " 'rels': [{'id': 'P26',\n",
      "           'prefix': 'wdt:',\n",
      "           'uri': 'http://www.wikidata.org/prop/direct/P26'},\n",
      "          {'id': 'P2848',\n",
      "           'prefix': 'wdt:',\n",
      "           'uri': 'http://www.wikidata.org/prop/direct/P2848'},\n",
      "          {'id': 'P140',\n",
      "           'prefix': 'wdt:',\n",
      "           'uri': 'http://www.wikidata.org/prop/direct/P140'},\n",
      "          {'id': 'P451',\n",
      "           'prefix': 'wdt:',\n",
      "           'uri': 'http://www.wikidata.org/prop/direct/P451'},\n",
      "          {'id': 'P600',\n",
      "           'prefix': 'wdt:',\n",
      "           'uri': 'http://www.wikidata.org/prop/direct/P600'}],\n",
      " 'utterance': 'Who is the wife of Barack Obama'}\n",
      "'Annotated'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fragments': ['[DEF]',\n",
      "               'wd:',\n",
      "               'Q76 Barack Obama',\n",
      "               '[DEF]',\n",
      "               'wd:',\n",
      "               'Q649593 Barack Obama Sr.',\n",
      "               '[DEF]',\n",
      "               'wd:',\n",
      "               'Q4808526 assassination threats against Barack Obama',\n",
      "               '[DEF]',\n",
      "               'wd:',\n",
      "               'Q4858106 Barack Obama Academy',\n",
      "               '[DEF]',\n",
      "               'wd:',\n",
      "               'Q643049 family of Barack Obama',\n",
      "               '[DEF]',\n",
      "               'wdt:',\n",
      "               'P26 spouse',\n",
      "               '[DEF]',\n",
      "               'wdt:',\n",
      "               'P2848 Wi-Fi access',\n",
      "               '[DEF]',\n",
      "               'wdt:',\n",
      "               'P140 religion',\n",
      "               '[DEF]',\n",
      "               'wdt:',\n",
      "               'P451 unmarried partner',\n",
      "               '[DEF]',\n",
      "               'wdt:',\n",
      "               'P600 Wine AppDB ID'],\n",
      " 'utterance': 'Who is the wife of Barack Obama'}\n",
      "'Converted'\n",
      "('Who is the wife of Barack Obama <extra_id_59> <extra_id_53> Q76 Barack Obama '\n",
      " '<extra_id_59> <extra_id_53> Q649593 Barack Obama Sr. <extra_id_59> '\n",
      " '<extra_id_53> Q4808526 assassination threats against Barack Obama '\n",
      " '<extra_id_59> <extra_id_53> Q4858106 Barack Obama Academy <extra_id_59> '\n",
      " '<extra_id_53> Q643049 family of Barack Obama <extra_id_59> <extra_id_54> P26 '\n",
      " 'spouse <extra_id_59> <extra_id_54> P2848 Wi-Fi access <extra_id_59> '\n",
      " '<extra_id_54> P140 religion <extra_id_59> <extra_id_54> P451 unmarried '\n",
      " 'partner <extra_id_59> <extra_id_54> P600 Wine AppDB ID')\n"
     ]
    }
   ],
   "source": [
    "linked = linker.link(utterance)\n",
    "# rules = [1,2,3,4,5,8,9,10,12,13,14]\n",
    "# linked = process_text_E_R(utterance, rules)\n",
    "pprint(\"Linked\")\n",
    "pprint(linked)\n",
    "\n",
    "pprint(\"Annotated\")\n",
    "annotated = annotator.annotate(**linked)\n",
    "pprint(annotated)\n",
    "\n",
    "pprint(\"Converted\")\n",
    "converted = converter.preprocess_inputs(**annotated)\n",
    "pprint(converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d615e909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T15:01:55.493358Z",
     "iopub.status.busy": "2023-07-12T15:01:55.492940Z",
     "iopub.status.idle": "2023-07-12T15:01:55.496421Z",
     "shell.execute_reply": "2023-07-12T15:01:55.495812Z"
    },
    "papermill": {
     "duration": 0.007001,
     "end_time": "2023-07-12T15:01:55.497299",
     "exception": false,
     "start_time": "2023-07-12T15:01:55.490298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pipe(utterance, wikisparql):\n",
    "    linked = linker.link(utterance)\n",
    "    annotated = annotator.annotate(**linked)\n",
    "    converted = converter.preprocess(**annotated, wikisparql=wikisparql)\n",
    "    return linked, annotated, converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12839a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T15:01:55.500062Z",
     "iopub.status.busy": "2023-07-12T15:01:55.499847Z",
     "iopub.status.idle": "2023-07-12T15:01:55.502950Z",
     "shell.execute_reply": "2023-07-12T15:01:55.502550Z"
    },
    "papermill": {
     "duration": 0.005095,
     "end_time": "2023-07-12T15:01:55.503561",
     "exception": false,
     "start_time": "2023-07-12T15:01:55.498466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pipe_batch(utterances, wikisparqls):\n",
    "  batched = []\n",
    "  link_batch_start = time.time()\n",
    "  linked = linker.link_batch(utterances)\n",
    "  link_batch_end = time.time()\n",
    "  annotator_time = 0\n",
    "  converter_time = 0\n",
    "  for i, single_linked in enumerate(linked):\n",
    "    s = time.time()\n",
    "    annotated = annotator.annotate(**single_linked)\n",
    "    e = time.time()\n",
    "    try:\n",
    "      annotator_time += e - s\n",
    "    except Exception as e:\n",
    "      print(\"[Annotator Error]:\", e)\n",
    "      continue\n",
    "    s = time.time()\n",
    "    try:\n",
    "      converted = converter.preprocess(**annotated, wikisparql=wikisparqls[i])\n",
    "    except Exception as e:\n",
    "      print(\"[Converter Error]:\", e)\n",
    "      continue\n",
    "      \n",
    "    e = time.time()\n",
    "    converter_time += e - s\n",
    "    batched.append([single_linked, annotated, converted])\n",
    "  print(\"Link batch time:\", link_batch_end - link_batch_start)\n",
    "  print(\"Anno batch time:\", annotator_time)\n",
    "  print(\"Conv batch time:\", converter_time)\n",
    "  return batched"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd8de25",
   "metadata": {
    "papermill": {
     "duration": 0.001097,
     "end_time": "2023-07-12T15:01:55.505919",
     "exception": false,
     "start_time": "2023-07-12T15:01:55.504822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3bd4ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T15:01:55.508475Z",
     "iopub.status.busy": "2023-07-12T15:01:55.508252Z",
     "iopub.status.idle": "2023-07-12T15:01:55.573113Z",
     "shell.execute_reply": "2023-07-12T15:01:55.572691Z"
    },
    "papermill": {
     "duration": 0.06705,
     "end_time": "2023-07-12T15:01:55.573947",
     "exception": false,
     "start_time": "2023-07-12T15:01:55.506897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data_path = Path(\"..\") / \"t5-for-sparql\" / \"data\" / \"lcquad2\" / \"train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff3ddde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T15:01:55.576748Z",
     "iopub.status.busy": "2023-07-12T15:01:55.576537Z",
     "iopub.status.idle": "2023-07-12T15:01:55.696278Z",
     "shell.execute_reply": "2023-07-12T15:01:55.695889Z"
    },
    "papermill": {
     "duration": 0.121958,
     "end_time": "2023-07-12T15:01:55.697008",
     "exception": false,
     "start_time": "2023-07-12T15:01:55.575050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNQT_question</th>\n",
       "      <th>uid</th>\n",
       "      <th>subgraph</th>\n",
       "      <th>template_index</th>\n",
       "      <th>question</th>\n",
       "      <th>sparql_wikidata</th>\n",
       "      <th>sparql_dbpedia18</th>\n",
       "      <th>template</th>\n",
       "      <th>answer</th>\n",
       "      <th>template_id</th>\n",
       "      <th>paraphrased_question</th>\n",
       "      <th>new_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the {periodical literature} for {mouth...</td>\n",
       "      <td>19719</td>\n",
       "      <td>simple question right</td>\n",
       "      <td>65</td>\n",
       "      <td>What periodical literature does Delta Air Line...</td>\n",
       "      <td>select distinct ?obj where { wd:Q188920 wdt:P...</td>\n",
       "      <td>select distinct ?obj where { ?statement &lt;http:...</td>\n",
       "      <td>&lt;S P ?O ; ?O instanceOf Type&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>What is Delta Air Line's periodical literature...</td>\n",
       "      <td>What is Delta Air Line's periodical literature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is {child of} of {husband} of {Ranavalona...</td>\n",
       "      <td>15554</td>\n",
       "      <td>left-subgraph</td>\n",
       "      <td>8</td>\n",
       "      <td>Who is the child of Ranavalona I's husband?</td>\n",
       "      <td>SELECT ?answer WHERE { wd:Q169794 wdt:P26 ?X ....</td>\n",
       "      <td>SELECT ?answer WHERE { ?statement1 &lt;http://www...</td>\n",
       "      <td>C RCD xD . xD RDE ?E</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>What is the name of Ranavalona I's husband's c...</td>\n",
       "      <td>What is the name of Ranavalona I's husband's c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did {Jeff_Bridges} {occupation} {Lane Chandler...</td>\n",
       "      <td>974</td>\n",
       "      <td>boolean double one_hop right subgraph</td>\n",
       "      <td>474</td>\n",
       "      <td>Is it true Jeff_Bridges occupation Lane Chandl...</td>\n",
       "      <td>ASK WHERE { wd:Q174843 wdt:P106 wd:Q1804811 . ...</td>\n",
       "      <td>ASK { ?statement1 &lt;http://www.w3.org/1999/02/...</td>\n",
       "      <td>Ask (ent-pred-obj1` . ent-pred-obj2)</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>Are Jeff Bridges and Lane Chandler both photog...</td>\n",
       "      <td>Are Jeff Bridges and Lane Chandler both photog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is {prequel of} of {phase of matter} of {...</td>\n",
       "      <td>15803</td>\n",
       "      <td>right-subgraph</td>\n",
       "      <td>33</td>\n",
       "      <td>What is the pre-requisite of phase matter of G...</td>\n",
       "      <td>SELECT ?answer WHERE { wd:Q675176 wdt:P515 ?X ...</td>\n",
       "      <td>SELECT ?answer WHERE { ?statement1 &lt;http://www...</td>\n",
       "      <td>E REF xF . xF RFG ?G</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>What range are the papers at the Monique Genon...</td>\n",
       "      <td>What range are the papers at the Monique Genon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is &lt;operating income&gt; of &lt;Qantas&gt; ?</td>\n",
       "      <td>27610</td>\n",
       "      <td>center</td>\n",
       "      <td>1907</td>\n",
       "      <td>Which is the operating income for Qantas?</td>\n",
       "      <td>select distinct ?answer where { wd:Q32491 wdt:...</td>\n",
       "      <td>select distinct ?answer where { ?statement &lt;ht...</td>\n",
       "      <td>E REF ?F</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Which is the operating income for Qantas?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       NNQT_question    uid  \\\n",
       "0  What is the {periodical literature} for {mouth...  19719   \n",
       "1  What is {child of} of {husband} of {Ranavalona...  15554   \n",
       "2  Did {Jeff_Bridges} {occupation} {Lane Chandler...    974   \n",
       "3  What is {prequel of} of {phase of matter} of {...  15803   \n",
       "4           What is <operating income> of <Qantas> ?  27610   \n",
       "\n",
       "                                subgraph  template_index  \\\n",
       "0                  simple question right              65   \n",
       "1                          left-subgraph               8   \n",
       "2  boolean double one_hop right subgraph             474   \n",
       "3                         right-subgraph              33   \n",
       "4                                 center            1907   \n",
       "\n",
       "                                            question  \\\n",
       "0  What periodical literature does Delta Air Line...   \n",
       "1        Who is the child of Ranavalona I's husband?   \n",
       "2  Is it true Jeff_Bridges occupation Lane Chandl...   \n",
       "3  What is the pre-requisite of phase matter of G...   \n",
       "4          Which is the operating income for Qantas?   \n",
       "\n",
       "                                     sparql_wikidata  \\\n",
       "0   select distinct ?obj where { wd:Q188920 wdt:P...   \n",
       "1  SELECT ?answer WHERE { wd:Q169794 wdt:P26 ?X ....   \n",
       "2  ASK WHERE { wd:Q174843 wdt:P106 wd:Q1804811 . ...   \n",
       "3  SELECT ?answer WHERE { wd:Q675176 wdt:P515 ?X ...   \n",
       "4  select distinct ?answer where { wd:Q32491 wdt:...   \n",
       "\n",
       "                                    sparql_dbpedia18  \\\n",
       "0  select distinct ?obj where { ?statement <http:...   \n",
       "1  SELECT ?answer WHERE { ?statement1 <http://www...   \n",
       "2   ASK { ?statement1 <http://www.w3.org/1999/02/...   \n",
       "3  SELECT ?answer WHERE { ?statement1 <http://www...   \n",
       "4  select distinct ?answer where { ?statement <ht...   \n",
       "\n",
       "                               template answer template_id  \\\n",
       "0         <S P ?O ; ?O instanceOf Type>     []           1   \n",
       "1                  C RCD xD . xD RDE ?E     []           5   \n",
       "2  Ask (ent-pred-obj1` . ent-pred-obj2)     []           2   \n",
       "3                  E REF xF . xF RFG ?G     []           2   \n",
       "4                              E REF ?F     []         1.1   \n",
       "\n",
       "                                paraphrased_question  \\\n",
       "0  What is Delta Air Line's periodical literature...   \n",
       "1  What is the name of Ranavalona I's husband's c...   \n",
       "2  Are Jeff Bridges and Lane Chandler both photog...   \n",
       "3  What range are the papers at the Monique Genon...   \n",
       "4                                                 []   \n",
       "\n",
       "                                        new_question  \n",
       "0  What is Delta Air Line's periodical literature...  \n",
       "1  What is the name of Ranavalona I's husband's c...  \n",
       "2  Are Jeff Bridges and Lane Chandler both photog...  \n",
       "3  What range are the papers at the Monique Genon...  \n",
       "4          Which is the operating income for Qantas?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(data_path) as f:\n",
    "  data_dict = json.load(f)\n",
    "\n",
    "for item in data_dict:\n",
    "  paraphrased_question = item[\"paraphrased_question\"]\n",
    "  question = item[\"question\"]\n",
    "  item[\"new_question\"] = paraphrased_question if len(paraphrased_question) > 2 else question\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d648fcc",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63bd9cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T15:01:55.699990Z",
     "iopub.status.busy": "2023-07-12T15:01:55.699764Z",
     "iopub.status.idle": "2023-07-12T17:04:23.421845Z",
     "shell.execute_reply": "2023-07-12T17:04:23.421301Z"
    },
    "papermill": {
     "duration": 7347.72879,
     "end_time": "2023-07-12T17:04:23.427001",
     "exception": true,
     "start_time": "2023-07-12T15:01:55.698211",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline iter 0\n",
      "Pipeline iter 1\n",
      "Pipeline iter 2\n",
      "Pipeline iter 3\n",
      "Pipeline iter 4\n",
      "Pipeline iter 5\n",
      "Pipeline iter 6\n",
      "Pipeline iter 7\n",
      "Pipeline iter 8\n",
      "Pipeline iter 9\n",
      "Pipeline iter 10\n",
      "Pipeline iter 11\n",
      "Pipeline iter 12\n",
      "Pipeline iter 13\n",
      "Pipeline iter 14\n",
      "Pipeline iter 15\n",
      "Pipeline iter 16\n",
      "Pipeline iter 17\n",
      "Pipeline iter 18\n",
      "Pipeline iter 19\n",
      "Pipeline iter 20\n",
      "Pipeline iter 21\n",
      "Pipeline iter 22\n",
      "Pipeline iter 23\n",
      "Pipeline iter 24\n",
      "Pipeline iter 25\n",
      "Pipeline iter 26\n",
      "Pipeline iter 27\n",
      "Pipeline iter 28\n",
      "Pipeline iter 29\n",
      "Pipeline iter 30\n",
      "Pipeline iter 31\n",
      "Pipeline iter 32\n",
      "Pipeline iter 33\n",
      "Pipeline iter 34\n",
      "Pipeline iter 35\n",
      "Pipeline iter 36\n",
      "Pipeline iter 37\n",
      "Pipeline iter 38\n",
      "Pipeline iter 39\n",
      "Pipeline iter 40\n",
      "Pipeline iter 41\n",
      "Pipeline iter 42\n",
      "Pipeline iter 43\n",
      "Pipeline iter 44\n",
      "Pipeline iter 45\n",
      "Pipeline iter 46\n",
      "Pipeline iter 47\n",
      "Pipeline iter 48\n",
      "Pipeline iter 49\n",
      "[Pipeline1]: Linking 0-49\n",
      "1 : ['What is Delta Air Lines periodical literature mouthpiece?']\n",
      "1 : ['What is the name of Ranavalona Is husbands child?']\n",
      "1 : ['Are Jeff Bridges and Lane Chandler both photographers?']\n",
      "1 : ['What range are the papers at the Monique Genonceaux about?']\n",
      "1 : ['Which is the operating income for Qantas?']\n",
      "1 : ['which cola begins with the letter p']\n",
      "1 : ['Does malin 1 have a right ascension lower than 15.1398?']\n",
      "1 : ['What is the total list of records discharged by Jerry Lee Lewis?']\n",
      "1 : ['What is Mary Lou Rettons International Olympic Committee athlete ID.']\n",
      "1 : ['Who won the prize at the spin-off of the 1885 Wimbledon Championships- Gentlemens Singles?']\n",
      "1 : ['Does the iPhone X Max have a carbon footprint of 106?']\n",
      "1 : ['Tell me the female splendor festival that operates in all countries and contains the phrase model in it is name?']\n",
      "1 : ['In 1999 and 2019, was Lindsey Vonn in the FIS Alpine World Ski Championships?']\n",
      "1 : ['On November 10, 1994, what was Angela Merkels role?']\n",
      "1 : ['What was the population of Spokane at the beginning of 2007?']\n",
      "1 : ['What basic pharmaceutical is required to treat leprosy?']\n",
      "1 : ['Which is HanCinema person ID for Zhang Ziyi?']\n",
      "1 : ['Was the Tony Award for best direction of the play Premium Imperiale given to Judi Densch?']\n",
      "1 : ['Copper as 4703.0 has a boiling boint of what?']\n",
      "1 : ['why Marathon had this name and the current record is?']\n",
      "1 : ['Who Sleepwalking succeeded in playing Sleepwalking?']\n",
      "1 : ['In 1983, what nomination did Clifton Chenier receive?']\n",
      "1 : ['Which is the wear for Ambrose Burnside?']\n",
      "1 : ['What flammable liquid has the least lower flammable limit in Class IB?']\n",
      "1 : ['What is the material used and accredited by means of Mojito?']\n",
      "1 : ['In this topic, give a summary of Koreas history']\n",
      "1 : ['Which is {scene of} of {Virgin of the rocks}, which has {birth city} is {Tzippori} ?']\n",
      "1 : ['Is the Fielders Stadium owned by Kevin Costner?']\n",
      "1 : ['Which is the YouTube channel ID for Miley Cyrus?']\n",
      "1 : ['What could be a aptitude that begins with the letter s.']\n",
      "1 : ['Give me the dimensions of Captain America']\n",
      "1 : ['What award did Danila Kozlovsky get in 2017?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : ['Who is the understudy that coined the Euler-Lagrange equation?']\n",
      "3 : ['Which website does Twitch own?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 : ['Is the negligible deadly dosage of the benzene rise to to 170000?']\n",
      "5 : ['Who is the person Ivan Pavlovs student?']\n",
      "[reRank_relations]: are Jeff Bridges and Lane Chandler both photographers \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which website does Twitch own \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "[reRank_relations]: which website does Twitch own \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "6 : ['is the clock speed of the Watara Supervision littler than 3.2?']\n",
      "[reRank_relations]: who Sleepwalking succeeded in playing Sleepwalking \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "7 : ['What country leads the African Union?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is HanCinema person ID for Zhang Ziyi \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 0.9291884899139404 \n",
      "SPARQL Avg Time per Qn: 0.9291884899139404\n",
      "[reRank_relations]: which is HanCinema person ID for Zhang Ziyi \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "8 : ['The accused Mariposa Folk Festival in 1974 employed whom?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 : ['N / A N / A']\n",
      "10 : ['Which sister city in Zakhar Oskotsky was born?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what was the population of Spokane at the beginning of 2007 \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 0.7490642070770264 \n",
      "SPARQL Avg Time per Qn: 0.7490642070770264\n",
      "11 : ['Let me know the title of a fantastique sort that begins with the letter s.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 : ['What is the medal Angela Lansbury recieved?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is the YouTube channel ID for Miley Cyrus \n",
      "SPARQL Requests Made: 3 \n",
      "SPARQL Requests Total Time: 2.377039670944214 \n",
      "SPARQL Avg Time per Qn: 0.7923465569814047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which sister city in Zakhar Oskotsky was born \n",
      "SPARQL Requests Made: 2 \n",
      "SPARQL Requests Total Time: 2.055117130279541 \n",
      "SPARQL Avg Time per Qn: 1.0275585651397705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which sister city in Zakhar Oskotsky was born \n",
      "SPARQL Requests Made: 3 \n",
      "SPARQL Requests Total Time: 2.225595712661743 \n",
      "SPARQL Avg Time per Qn: 0.7418652375539144\n",
      "[reRank_relations]: which sister city in Zakhar Oskotsky was born \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "13 : ['What is the musical rating by means of Missa Solemnis that has mother Maria Magdalena van Beethoven?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who won the prize at the spin-off of the 1885 Wimbledon Championships- Gentlemens Singles \n",
      "SPARQL Requests Made: 5 \n",
      "SPARQL Requests Total Time: 3.93013334274292 \n",
      "SPARQL Avg Time per Qn: 0.7860266685485839\n",
      "14 : ['When did Robert De Nirolive in Marbletown?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is the operating income for Qantas \n",
      "SPARQL Requests Made: 8 \n",
      "SPARQL Requests Total Time: 6.118624925613403 \n",
      "SPARQL Avg Time per Qn: 0.7648281157016754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is the operating income for Qantas \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 0.7748544216156006 \n",
      "SPARQL Avg Time per Qn: 0.7748544216156006\n",
      "15 : ['Let me know organization whose title has the word zollkriminalamt in it.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: was the Tony Award for best direction of the play Premium Imperiale given to Judi Densch \n",
      "SPARQL Requests Made: 9 \n",
      "SPARQL Requests Total Time: 6.770498514175415 \n",
      "SPARQL Avg Time per Qn: 0.7522776126861572\n",
      "[reRank_relations]: was the Tony Award for best direction of the play Premium Imperiale given to Judi Densch \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "16 : ['Which country in the International Centre for Settlement of Investment Disputes has the highest inflation rate?']\n",
      "[reRank_relations]: does malin 1 have a right ascension lower than 151398 \n",
      "SPARQL Requests Made: 9 \n",
      "SPARQL Requests Total Time: 7.189099073410034 \n",
      "SPARQL Avg Time per Qn: 0.7987887859344482\n",
      "17 : ['Did Brittany Murphy have USA citizenship?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: is the Fielders Stadium owned by Kevin Costner \n",
      "SPARQL Requests Made: 12 \n",
      "SPARQL Requests Total Time: 9.634251832962036 \n",
      "SPARQL Avg Time per Qn: 0.802854319413503\n",
      "[reRank_relations]: is the Fielders Stadium owned by Kevin Costner \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "18 : ['Who is Hank Azaria married to ?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who is Hank Azaria married to  \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 0.7382204532623291 \n",
      "SPARQL Avg Time per Qn: 0.7382204532623291\n",
      "[reRank_relations]: who is Hank Azaria married to  \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "19 : ['Is 11 the maximum age of St. Peters Junior School?']\n",
      "[reRank_relations]: which is the wear for Ambrose Burnside \n",
      "SPARQL Requests Made: 13 \n",
      "SPARQL Requests Total Time: 9.911734104156494 \n",
      "SPARQL Avg Time per Qn: 0.762441084935115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: when did Robert De Nirolive in Marbletown \n",
      "SPARQL Requests Made: 10 \n",
      "SPARQL Requests Total Time: 7.556022644042969 \n",
      "SPARQL Avg Time per Qn: 0.7556022644042969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is Mary Lou Rettons International Olympic Committee athlete ID \n",
      "SPARQL Requests Made: 18 \n",
      "SPARQL Requests Total Time: 13.399070501327515 \n",
      "SPARQL Avg Time per Qn: 0.7443928056293063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is the YouTube channel ID for Miley Cyrus \n",
      "SPARQL Requests Made: 15 \n",
      "SPARQL Requests Total Time: 11.643294334411621 \n",
      "SPARQL Avg Time per Qn: 0.7762196222941081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: why Marathon had this name and the current record is \n",
      "SPARQL Requests Made: 20 \n",
      "SPARQL Requests Total Time: 14.9544677734375 \n",
      "SPARQL Avg Time per Qn: 0.747723388671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which country in the International Centre for Settlement of Investment Disputes has the highest inflation rate \n",
      "SPARQL Requests Made: 18 \n",
      "SPARQL Requests Total Time: 13.960193872451782 \n",
      "SPARQL Avg Time per Qn: 0.7755663262473212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who Sleepwalking succeeded in playing Sleepwalking \n",
      "SPARQL Requests Made: 28 \n",
      "SPARQL Requests Total Time: 21.105658292770386 \n",
      "SPARQL Avg Time per Qn: 0.7537735104560852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the total list of records discharged by Jerry Lee Lewis \n",
      "SPARQL Requests Made: 30 \n",
      "SPARQL Requests Total Time: 23.810672760009766 \n",
      "SPARQL Avg Time per Qn: 0.7936890920003256\n",
      "[reRank_relations]: what is the total list of records discharged by Jerry Lee Lewis \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the name of Ranavalona Is husbands child \n",
      "SPARQL Requests Made: 72 \n",
      "SPARQL Requests Total Time: 54.50242042541504 \n",
      "SPARQL Avg Time per Qn: 0.7569780614640977\n",
      "[reRank_relations]: what is the name of Ranavalona Is husbands child \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what basic pharmaceutical is required to treat Leprosy \n",
      "SPARQL Requests Made: 79 \n",
      "SPARQL Requests Total Time: 59.9490327835083 \n",
      "SPARQL Avg Time per Qn: 0.7588485162469405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the material used and accredited by means of Mojito \n",
      "SPARQL Requests Made: 90 \n",
      "SPARQL Requests Total Time: 68.50403046607971 \n",
      "SPARQL Avg Time per Qn: 0.7611558940675524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what country leads the African Union \n",
      "SPARQL Requests Made: 90 \n",
      "SPARQL Requests Total Time: 68.149569272995 \n",
      "SPARQL Avg Time per Qn: 0.7572174363666111\n",
      "[reRank_relations]: what is the medal Angela Lansbury recieved \n",
      "SPARQL Requests Made: 91 \n",
      "SPARQL Requests Total Time: 69.140949010849 \n",
      "SPARQL Avg Time per Qn: 0.7597906484708681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who is the person Ivan Pavlovs student \n",
      "SPARQL Requests Made: 93 \n",
      "SPARQL Requests Total Time: 70.29634046554565 \n",
      "SPARQL Avg Time per Qn: 0.7558746286617812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what country leads the African Union \n",
      "SPARQL Requests Made: 3 \n",
      "SPARQL Requests Total Time: 2.257725954055786 \n",
      "SPARQL Avg Time per Qn: 0.7525753180185953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the medal Angela Lansbury recieved \n",
      "SPARQL Requests Made: 5 \n",
      "SPARQL Requests Total Time: 3.7302370071411133 \n",
      "SPARQL Avg Time per Qn: 0.7460474014282227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: did Brittany Murphy have USA citizenship \n",
      "SPARQL Requests Made: 93 \n",
      "SPARQL Requests Total Time: 72.58974146842957 \n",
      "SPARQL Avg Time per Qn: 0.7805348544992426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: the accused Mariposa Folk Festival in 1974 employed whom \n",
      "SPARQL Requests Made: 104 \n",
      "SPARQL Requests Total Time: 80.60512924194336 \n",
      "SPARQL Avg Time per Qn: 0.7750493196340708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: is the clock speed of the Watara Supervision littler than 32 \n",
      "SPARQL Requests Made: 106 \n",
      "SPARQL Requests Total Time: 81.85151267051697 \n",
      "SPARQL Avg Time per Qn: 0.7721840817973299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what basic pharmaceutical is required to treat Leprosy \n",
      "SPARQL Requests Made: 32 \n",
      "SPARQL Requests Total Time: 24.105208158493042 \n",
      "SPARQL Avg Time per Qn: 0.7532877549529076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: in 1983, what nomination did Clifton Chenier receive \n",
      "SPARQL Requests Made: 122 \n",
      "SPARQL Requests Total Time: 93.53721952438354 \n",
      "SPARQL Avg Time per Qn: 0.7666985206916684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: are Jeff Bridges and Lane Chandler both photographers \n",
      "SPARQL Requests Made: 123 \n",
      "SPARQL Requests Total Time: 94.47390270233154 \n",
      "SPARQL Avg Time per Qn: 0.7680805097750532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: tell me the female splendor festival that operates in all countries and contains the phrase model in it is name \n",
      "SPARQL Requests Made: 125 \n",
      "SPARQL Requests Total Time: 95.90695834159851 \n",
      "SPARQL Avg Time per Qn: 0.7672556667327881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: tell me the female splendor festival that operates in all countries and contains the phrase model in it is name \n",
      "SPARQL Requests Made: 9 \n",
      "SPARQL Requests Total Time: 6.829360723495483 \n",
      "SPARQL Avg Time per Qn: 0.7588178581661649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what award did Danila Kozlovsky get in 2017 \n",
      "SPARQL Requests Made: 136 \n",
      "SPARQL Requests Total Time: 106.48287582397461 \n",
      "SPARQL Avg Time per Qn: 0.7829623222351074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what award did Danila Kozlovsky get in 2017 \n",
      "SPARQL Requests Made: 10 \n",
      "SPARQL Requests Total Time: 7.62560510635376 \n",
      "SPARQL Avg Time per Qn: 0.762560510635376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: the accused Mariposa Folk Festival in 1974 employed whom \n",
      "SPARQL Requests Made: 60 \n",
      "SPARQL Requests Total Time: 46.66016697883606 \n",
      "SPARQL Avg Time per Qn: 0.7776694496472677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who is the Understudy that coined the Euler-Lagrange equation \n",
      "SPARQL Requests Made: 166 \n",
      "SPARQL Requests Total Time: 129.0163791179657 \n",
      "SPARQL Avg Time per Qn: 0.7772071031202753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what range are the papers at the Monique Genonceaux about \n",
      "SPARQL Requests Made: 210 \n",
      "SPARQL Requests Total Time: 161.8237292766571 \n",
      "SPARQL Avg Time per Qn: 0.7705891870317005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: let me know the title of a fantastique sort that begins with the letter s \n",
      "SPARQL Requests Made: 226 \n",
      "SPARQL Requests Total Time: 176.32419419288635 \n",
      "SPARQL Avg Time per Qn: 0.7801955495260459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: in 1999 and 2019, was Lindsey Vonn in the FIS Alpine World Ski Championships \n",
      "SPARQL Requests Made: 231 \n",
      "SPARQL Requests Total Time: 179.19188380241394 \n",
      "SPARQL Avg Time per Qn: 0.7757224407030906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the musical rating by means of Missa Solemnis that has mother Maria Magdalena van Beethoven \n",
      "SPARQL Requests Made: 226 \n",
      "SPARQL Requests Total Time: 174.96700811386108 \n",
      "SPARQL Avg Time per Qn: 0.7741903013887659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what flammable liquid has the least lower flammable limit in Class IB \n",
      "SPARQL Requests Made: 254 \n",
      "SPARQL Requests Total Time: 196.31135320663452 \n",
      "SPARQL Avg Time per Qn: 0.7728793433332067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: let me know organization whose title has the word zollkriminalamt in it \n",
      "SPARQL Requests Made: 246 \n",
      "SPARQL Requests Total Time: 189.71420216560364 \n",
      "SPARQL Avg Time per Qn: 0.7711959437626165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what flammable liquid has the least lower flammable limit in Class IB \n",
      "SPARQL Requests Made: 4 \n",
      "SPARQL Requests Total Time: 3.2270584106445312 \n",
      "SPARQL Avg Time per Qn: 0.8067646026611328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the material used and accredited by means of Mojito \n",
      "SPARQL Requests Made: 180 \n",
      "SPARQL Requests Total Time: 140.67341256141663 \n",
      "SPARQL Avg Time per Qn: 0.7815189586745368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who Sleepwalking succeeded in playing Sleepwalking \n",
      "SPARQL Requests Made: 270 \n",
      "SPARQL Requests Total Time: 211.22996926307678 \n",
      "SPARQL Avg Time per Qn: 0.7823332194928769\n",
      "[reRank_relations]: who Sleepwalking succeeded in playing Sleepwalking \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which cola begins with the letter p \n",
      "SPARQL Requests Made: 306 \n",
      "SPARQL Requests Total Time: 239.28679990768433 \n",
      "SPARQL Avg Time per Qn: 0.7819830062342625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: tell me the female splendor festival that operates in all countries and contains the phrase model in it is name \n",
      "SPARQL Requests Made: 242 \n",
      "SPARQL Requests Total Time: 188.76090931892395 \n",
      "SPARQL Avg Time per Qn: 0.7800037575162146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what could be a aptitude that begins with the letter s \n",
      "SPARQL Requests Made: 390 \n",
      "SPARQL Requests Total Time: 306.2114737033844 \n",
      "SPARQL Avg Time per Qn: 0.7851576248804728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on November 10, 1994, what was Angela Merkels role \n",
      "SPARQL Requests Made: 450 \n",
      "SPARQL Requests Total Time: 350.0164723396301 \n",
      "SPARQL Avg Time per Qn: 0.7778143829769558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the musical rating by means of Missa Solemnis that has mother Maria Magdalena van Beethoven \n",
      "SPARQL Requests Made: 226 \n",
      "SPARQL Requests Total Time: 177.58531546592712 \n",
      "SPARQL Avg Time per Qn: 0.78577573215012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: let me know the title of a fantastique sort that begins with the letter s \n",
      "SPARQL Requests Made: 391 \n",
      "SPARQL Requests Total Time: 305.59955620765686 \n",
      "SPARQL Avg Time per Qn: 0.7815845427305802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: let me know the title of a fantastique sort that begins with the letter s \n",
      "SPARQL Requests Made: 115 \n",
      "SPARQL Requests Total Time: 88.662837266922 \n",
      "SPARQL Avg Time per Qn: 0.7709811936254086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on November 10, 1994, what was Angela Merkels role \n",
      "SPARQL Requests Made: 450 \n",
      "SPARQL Requests Total Time: 350.1318962574005 \n",
      "SPARQL Avg Time per Qn: 0.7780708805720011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index error, no label found for\n",
      "wdt::P1773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index error, no label found for\n",
      "wd::Q228087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link batch time: 1402.3730001449585\n",
      "Anno batch time: 578.5341851711273\n",
      "Conv batch time: 0.003742694854736328\n",
      "Pipeline iter 50\n",
      "Pipeline iter 51\n",
      "Pipeline iter 52\n",
      "Pipeline iter 53\n",
      "Pipeline iter 54\n",
      "Pipeline iter 55\n",
      "Pipeline iter 56\n",
      "Pipeline iter 57\n",
      "Pipeline iter 58\n",
      "Pipeline iter 59\n",
      "Pipeline iter 60\n",
      "Pipeline iter 61\n",
      "Pipeline iter 62\n",
      "Pipeline iter 63\n",
      "Pipeline iter 64\n",
      "Pipeline iter 65\n",
      "Pipeline iter 66\n",
      "Pipeline iter 67\n",
      "Pipeline iter 68\n",
      "Pipeline iter 69\n",
      "Pipeline iter 70\n",
      "Pipeline iter 71\n",
      "Pipeline iter 72\n",
      "Pipeline iter 73\n",
      "Pipeline iter 74\n",
      "Pipeline iter 75\n",
      "Pipeline iter 76\n",
      "Pipeline iter 77\n",
      "Pipeline iter 78\n",
      "Pipeline iter 79\n",
      "Pipeline iter 80\n",
      "Pipeline iter 81\n",
      "Pipeline iter 82\n",
      "Pipeline iter 83\n",
      "Pipeline iter 84\n",
      "Pipeline iter 85\n",
      "Pipeline iter 86\n",
      "Pipeline iter 87\n",
      "Pipeline iter 88\n",
      "Pipeline iter 89\n",
      "Pipeline iter 90\n",
      "Pipeline iter 91\n",
      "Pipeline iter 92\n",
      "Pipeline iter 93\n",
      "Pipeline iter 94\n",
      "Pipeline iter 95\n",
      "Pipeline iter 96\n",
      "Pipeline iter 97\n",
      "Pipeline iter 98\n",
      "Pipeline iter 99\n",
      "[Pipeline1]: Linking 49-99\n",
      "51 : ['What country has the highest taxes?']\n",
      "51 : ['What was the date that The St. Louis Literary Award was aquired by James Thomas Farrell.']\n",
      "51 : ['On what date did Pablo Picasso end his partnership with Fernade Oliver?']\n",
      "51 : ['What product that contains paraffin wax has the lowest usage per capita?']\n",
      "51 : ['Where is the geographic center of Michigan using the gravity center of the surface?']\n",
      "51 : ['In Indonesia, is the average life expectancy 55.3528?']\n",
      "51 : ['What year did Emmerson Mnangagwa start at the University of Zambia?']\n",
      "51 : ['What kind of career in the screenwriting field does Grigori Kozintsev have?']\n",
      "51 : ['Which species is the ecia139-4120 protein found in?']\n",
      "51 : ['What majestic state supplanted the Kingdom of Incredible Britain?']\n",
      "51 : ['Of the century breaks of the Colm Gilcreest rise to less than 9.6?']\n",
      "51 : ['Where did the Golden Horde live in?']\n",
      "51 : ['Located in the Central District, what is the county seat whose twin cities include Feodosiya?']\n",
      "51 : ['In what year was Nicaraguas population 3.87732 million?']\n",
      "51 : ['What does emigration mean?']\n",
      "51 : ['The football association regulates what organization?']\n",
      "51 : ['When was the companion separated Nero in 9-6-68?']\n",
      "51 : ['Not applicable']\n",
      "51 : ['Former champion Francisco Alarcon gave what award to Art Spiegelaman?']\n",
      "51 : ['Are there more than survivors of the Charkhi Dadri mid-air collision']\n",
      "51 : ['On what date was Triple Crown Trophy given to Secretariat?']\n",
      "51 : ['Which borders of borders of Riverside have a begin date of 1984-0-0?']\n",
      "51 : ['Which is the facility of the defensive wall?']\n",
      "51 : ['What is  in the IHO Hydrographic Dictionary (S-32) Number of lighthouse ?']\n",
      "51 : ['Which is the fictional analog of Hippocampus?']\n",
      "51 : ['What is a purpose of dying that begins with the letter p and can be located on a CT scan?']\n",
      "51 : ['What is hooked up by way of Archbishop of Canterbury, who is a male?']\n",
      "51 : ['Where at Passy Cementery is Fernandel buried?']\n",
      "51 : ['How is the naval artillery wirh the smallest firing range called?']\n",
      "51 : ['What is the title of a Cayenne Pepper that too has dates?']\n",
      "51 : ['Does Vest-vassdraget have a throughput of 2697.672?']\n",
      "51 : ['wich method was used by the census to determine the population of Taguig?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 : ['Olga Tokarczuk was the winner of what award in 2015?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 : ['What is Porky Pig in right now?']\n",
      "54 : ['When did distributer of Pac-Man and put of publication?']\n",
      "[reRank_relations]: what majestic state supplanted the Kingdom of Incredible Britain \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "55 : ['Did Aleister Crowley receive his education at Trinity College and Eton College?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what kind of career in the screenwriting field does Grigori Kozintsev have \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "[reRank_relations]: what kind of career in the screenwriting field does Grigori Kozintsev have \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "56 : ['What is {located next to Quincy,} in the {novel, Infinite Jest}?']\n",
      "[reRank_relations]: what is a purpose of dying that begins with the letter p and can be located on a CT scan \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "[reRank_relations]: are there more than survivors of the Charkhi Dadri mid-air collision \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 0.7958314418792725 \n",
      "SPARQL Avg Time per Qn: 0.7958314418792725\n",
      "57 : ['Eric Hobsbawm was presented with an honorary doctorate by what institution?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 : ['In 1980 name the last team Allan Border played for?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what country has the highest taxes \n",
      "SPARQL Requests Made: 2 \n",
      "SPARQL Requests Total Time: 1.5295531749725342 \n",
      "SPARQL Avg Time per Qn: 0.7647765874862671\n",
      "59 : ['Give me a movie personality from a fictional universe, such as Marvel comics that starts with a W.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: where did the Golden Horde live in \n",
      "SPARQL Requests Made: 3 \n",
      "SPARQL Requests Total Time: 2.496767044067383 \n",
      "SPARQL Avg Time per Qn: 0.8322556813557943\n",
      "60 : ['Say the anecdotal universe depicted or included within The Framework.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: give me a movie personality from a fictional universe, such as Marvel comics that starts with a W \n",
      "SPARQL Requests Made: 2 \n",
      "SPARQL Requests Total Time: 1.5960938930511475 \n",
      "SPARQL Avg Time per Qn: 0.7980469465255737\n",
      "[reRank_relations]: which is the fictional analog of Hippocampus \n",
      "SPARQL Requests Made: 4 \n",
      "SPARQL Requests Total Time: 2.9509096145629883 \n",
      "SPARQL Avg Time per Qn: 0.7377274036407471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: in what year was Nicaraguas population 387732 million \n",
      "SPARQL Requests Made: 5 \n",
      "SPARQL Requests Total Time: 3.8234331607818604 \n",
      "SPARQL Avg Time per Qn: 0.7646866321563721\n",
      "61 : ['What is {grant gotten} of {Hans Krebs} where {point in time} is {1966-0-0} ?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: where at Passy Cementery is Fernandel buried \n",
      "SPARQL Requests Made: 6 \n",
      "SPARQL Requests Total Time: 4.622380256652832 \n",
      "SPARQL Avg Time per Qn: 0.7703967094421387\n",
      "[reRank_relations]: where at Passy Cementery is Fernandel buried \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "62 : ['What is the record label signed by Janet Jackson?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is the fictional analog of Hippocampus \n",
      "SPARQL Requests Made: 4 \n",
      "SPARQL Requests Total Time: 2.9963724613189697 \n",
      "SPARQL Avg Time per Qn: 0.7490931153297424\n",
      "63 : ['What is Tanzanias total reserves?']\n",
      "64 : ['Is the slope rating of the Merion Golf Club 149?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: is the slope rating of the Merion Golf Club 149 \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 0.7069201469421387 \n",
      "SPARQL Avg Time per Qn: 0.7069201469421387\n",
      "65 : ['What is hydrogen peroxides density at twenty degrees?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 : ['who engineering firm of domestic field of modern york centaurs?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the record label signed by Janet Jackson \n",
      "SPARQL Requests Made: 9 \n",
      "SPARQL Requests Total Time: 6.891653060913086 \n",
      "SPARQL Avg Time per Qn: 0.7657392289903429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the record label signed by Janet Jackson \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 0.8169941902160645 \n",
      "SPARQL Avg Time per Qn: 0.8169941902160645\n",
      "[reRank_relations]: what is the record label signed by Janet Jackson \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "67 : ['Which { meansseason starts} in {February} ?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on what date did Pablo Picasso end his partnership with Fernade Oliver \n",
      "SPARQL Requests Made: 17 \n",
      "SPARQL Requests Total Time: 13.428485870361328 \n",
      "SPARQL Avg Time per Qn: 0.7899109335506663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who engineering firm of domestic field of modern york centaurs \n",
      "SPARQL Requests Made: 15 \n",
      "SPARQL Requests Total Time: 11.352908611297607 \n",
      "SPARQL Avg Time per Qn: 0.7568605740865072\n",
      "68 : ['Who is {champ} of {prize granted} {Lily Tomlin} ?TARD ?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which { meansseason starts} in {February}  \n",
      "SPARQL Requests Made: 10 \n",
      "SPARQL Requests Total Time: 7.521719217300415 \n",
      "SPARQL Avg Time per Qn: 0.7521719217300415\n",
      "69 : ['What is the ammunition of the weapon, that has been used in the conflict in Southeast Asia?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what was the date that The St Louis Literary Award was aquired by James Thomas Farrell \n",
      "SPARQL Requests Made: 30 \n",
      "SPARQL Requests Total Time: 22.63758397102356 \n",
      "SPARQL Avg Time per Qn: 0.754586132367452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: when did distributer of Pac-Man and put of publication \n",
      "SPARQL Requests Made: 32 \n",
      "SPARQL Requests Total Time: 24.488598346710205 \n",
      "SPARQL Avg Time per Qn: 0.7652686983346939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what was the date that The St Louis Literary Award was aquired by James Thomas Farrell \n",
      "SPARQL Requests Made: 8 \n",
      "SPARQL Requests Total Time: 6.227419376373291 \n",
      "SPARQL Avg Time per Qn: 0.7784274220466614\n",
      "[reRank_relations]: what was the date that The St Louis Literary Award was aquired by James Thomas Farrell \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on what date did Pablo Picasso end his partnership with Fernade Oliver \n",
      "SPARQL Requests Made: 21 \n",
      "SPARQL Requests Total Time: 17.461416244506836 \n",
      "SPARQL Avg Time per Qn: 0.8314960116431827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what year did Emmerson Mnangagwa start at the University of Zambia \n",
      "SPARQL Requests Made: 42 \n",
      "SPARQL Requests Total Time: 31.82986092567444 \n",
      "SPARQL Avg Time per Qn: 0.7578538315636771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: did Aleister Crowley receive his education at Trinity College and Eton College \n",
      "SPARQL Requests Made: 43 \n",
      "SPARQL Requests Total Time: 32.87541961669922 \n",
      "SPARQL Avg Time per Qn: 0.764544642248819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: wich method was used by the census to determine the population of Taguig \n",
      "SPARQL Requests Made: 45 \n",
      "SPARQL Requests Total Time: 33.88816690444946 \n",
      "SPARQL Avg Time per Qn: 0.7530703756544325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: did Aleister Crowley receive his education at Trinity College and Eton College \n",
      "SPARQL Requests Made: 5 \n",
      "SPARQL Requests Total Time: 3.7167317867279053 \n",
      "SPARQL Avg Time per Qn: 0.7433463573455811\n",
      "[reRank_relations]: did Aleister Crowley receive his education at Trinity College and Eton College \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: give me a movie personality from a fictional universe, such as Marvel comics that starts with a W \n",
      "SPARQL Requests Made: 45 \n",
      "SPARQL Requests Total Time: 34.54573106765747 \n",
      "SPARQL Avg Time per Qn: 0.7676829126146104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what year did Emmerson Mnangagwa start at the University of Zambia \n",
      "SPARQL Requests Made: 8 \n",
      "SPARQL Requests Total Time: 5.907485485076904 \n",
      "SPARQL Avg Time per Qn: 0.738435685634613\n",
      "[reRank_relations]: what year did Emmerson Mnangagwa start at the University of Zambia \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: the football association regulates what organization \n",
      "SPARQL Requests Made: 50 \n",
      "SPARQL Requests Total Time: 38.923424243927 \n",
      "SPARQL Avg Time per Qn: 0.77846848487854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who is {champ} of {prize granted} {Lily Tomlin} TARD  \n",
      "SPARQL Requests Made: 29 \n",
      "SPARQL Requests Total Time: 22.95362615585327 \n",
      "SPARQL Avg Time per Qn: 0.791504350201837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the ammunition of the weapon, that has been used in the conflict in Southeast Asia \n",
      "SPARQL Requests Made: 30 \n",
      "SPARQL Requests Total Time: 22.95416808128357 \n",
      "SPARQL Avg Time per Qn: 0.7651389360427856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: when was the companion separated Nero in 9-6-68 \n",
      "SPARQL Requests Made: 60 \n",
      "SPARQL Requests Total Time: 45.06920862197876 \n",
      "SPARQL Avg Time per Qn: 0.7511534770329793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: eric Hobsbawm was presented with an honorary doctorate by what institution \n",
      "SPARQL Requests Made: 65 \n",
      "SPARQL Requests Total Time: 51.20755386352539 \n",
      "SPARQL Avg Time per Qn: 0.7878085209773137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the ammunition of the weapon, that has been used in the conflict in Southeast Asia \n",
      "SPARQL Requests Made: 22 \n",
      "SPARQL Requests Total Time: 17.65232515335083 \n",
      "SPARQL Avg Time per Qn: 0.8023784160614014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: olga Tokarczuk was the winner of what award in 2015 \n",
      "SPARQL Requests Made: 78 \n",
      "SPARQL Requests Total Time: 59.60751223564148 \n",
      "SPARQL Avg Time per Qn: 0.7641988748159164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: where is the geographic center of Michigan using the gravity center of the surface \n",
      "SPARQL Requests Made: 80 \n",
      "SPARQL Requests Total Time: 61.32059049606323 \n",
      "SPARQL Avg Time per Qn: 0.7665073812007904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: in 1980 name the last team Allan Border played for \n",
      "SPARQL Requests Made: 85 \n",
      "SPARQL Requests Total Time: 65.51066446304321 \n",
      "SPARQL Avg Time per Qn: 0.7707136995652143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: in 1980 name the last team Allan Border played for \n",
      "SPARQL Requests Made: 9 \n",
      "SPARQL Requests Total Time: 6.804749488830566 \n",
      "SPARQL Avg Time per Qn: 0.7560832765367296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on what date did Pablo Picasso end his partnership with Fernade Oliver \n",
      "SPARQL Requests Made: 60 \n",
      "SPARQL Requests Total Time: 47.89912533760071 \n",
      "SPARQL Avg Time per Qn: 0.7983187556266784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is  in the IHO Hydrographic Dictionary (S-32) Number of lighthouse  \n",
      "SPARQL Requests Made: 107 \n",
      "SPARQL Requests Total Time: 87.04305911064148 \n",
      "SPARQL Avg Time per Qn: 0.8134865337443129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: how is the naval artillery wirh the smallest firing range called \n",
      "SPARQL Requests Made: 114 \n",
      "SPARQL Requests Total Time: 87.46650862693787 \n",
      "SPARQL Avg Time per Qn: 0.7672500756748936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: located in the Central District, what is the county seat whose twin cities include Feodosiya \n",
      "SPARQL Requests Made: 120 \n",
      "SPARQL Requests Total Time: 95.69251155853271 \n",
      "SPARQL Avg Time per Qn: 0.797437596321106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: located in the Central District, what is the county seat whose twin cities include Feodosiya \n",
      "SPARQL Requests Made: 4 \n",
      "SPARQL Requests Total Time: 3.047658681869507 \n",
      "SPARQL Avg Time per Qn: 0.7619146704673767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is hooked up by way of Archbishop of Canterbury, who is a male \n",
      "SPARQL Requests Made: 135 \n",
      "SPARQL Requests Total Time: 103.38195705413818 \n",
      "SPARQL Avg Time per Qn: 0.7657922744750977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is hooked up by way of Archbishop of Canterbury, who is a male \n",
      "SPARQL Requests Made: 16 \n",
      "SPARQL Requests Total Time: 12.519986867904663 \n",
      "SPARQL Avg Time per Qn: 0.7824991792440414\n",
      "[reRank_relations]: what product that contains paraffin wax has the lowest usage per capita \n",
      "SPARQL Requests Made: 152 \n",
      "SPARQL Requests Total Time: 116.37541604042053 \n",
      "SPARQL Avg Time per Qn: 0.7656277371080298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on what date did Pablo Picasso end his partnership with Fernade Oliver \n",
      "SPARQL Requests Made: 60 \n",
      "SPARQL Requests Total Time: 45.823113679885864 \n",
      "SPARQL Avg Time per Qn: 0.7637185613314311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: wich method was used by the census to determine the population of Taguig \n",
      "SPARQL Requests Made: 121 \n",
      "SPARQL Requests Total Time: 92.44952416419983 \n",
      "SPARQL Avg Time per Qn: 0.7640456542495854\n",
      "[reRank_relations]: wich method was used by the census to determine the population of Taguig \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which borders of borders of Riverside have a begin date of 1984-0-0 \n",
      "SPARQL Requests Made: 165 \n",
      "SPARQL Requests Total Time: 127.3107008934021 \n",
      "SPARQL Avg Time per Qn: 0.7715800054145582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the title of a Cayenne Pepper that too has dates \n",
      "SPARQL Requests Made: 172 \n",
      "SPARQL Requests Total Time: 132.79967308044434 \n",
      "SPARQL Avg Time per Qn: 0.7720911225607229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on what date was Triple Crown Trophy given to Secretariat \n",
      "SPARQL Requests Made: 180 \n",
      "SPARQL Requests Total Time: 136.9707908630371 \n",
      "SPARQL Avg Time per Qn: 0.760948838127984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what does Emigration mean \n",
      "SPARQL Requests Made: 180 \n",
      "SPARQL Requests Total Time: 139.88163948059082 \n",
      "SPARQL Avg Time per Qn: 0.7771202193366157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is Porky Pig in right now \n",
      "SPARQL Requests Made: 188 \n",
      "SPARQL Requests Total Time: 147.66930174827576 \n",
      "SPARQL Avg Time per Qn: 0.7854750092993391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is the facility of the defensive wall \n",
      "SPARQL Requests Made: 195 \n",
      "SPARQL Requests Total Time: 150.8098645210266 \n",
      "SPARQL Avg Time per Qn: 0.7733839206206493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on what date was Triple Crown Trophy given to Secretariat \n",
      "SPARQL Requests Made: 29 \n",
      "SPARQL Requests Total Time: 23.20300579071045 \n",
      "SPARQL Avg Time per Qn: 0.8001036479555327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: say the anecdotal universe depicted or included within The Framework \n",
      "SPARQL Requests Made: 210 \n",
      "SPARQL Requests Total Time: 163.77923917770386 \n",
      "SPARQL Avg Time per Qn: 0.779901138941447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: olga Tokarczuk was the winner of what award in 2015 \n",
      "SPARQL Requests Made: 136 \n",
      "SPARQL Requests Total Time: 104.67650246620178 \n",
      "SPARQL Avg Time per Qn: 0.7696801651926601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on what date did Pablo Picasso end his partnership with Fernade Oliver \n",
      "SPARQL Requests Made: 60 \n",
      "SPARQL Requests Total Time: 46.06220054626465 \n",
      "SPARQL Avg Time per Qn: 0.7677033424377442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: of the century breaks of the Colm Gilcreest rise to less than 96 \n",
      "SPARQL Requests Made: 251 \n",
      "SPARQL Requests Total Time: 193.86010146141052 \n",
      "SPARQL Avg Time per Qn: 0.772351001838289\n",
      "[reRank_relations]: former champion Francisco Alarcon gave what award to Art Spiegelaman \n",
      "SPARQL Requests Made: 249 \n",
      "SPARQL Requests Total Time: 192.41450810432434 \n",
      "SPARQL Avg Time per Qn: 0.772749028531423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: former champion Francisco Alarcon gave what award to Art Spiegelaman \n",
      "SPARQL Requests Made: 20 \n",
      "SPARQL Requests Total Time: 15.668872594833374 \n",
      "SPARQL Avg Time per Qn: 0.7834436297416687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: say the anecdotal universe depicted or included within The Framework \n",
      "SPARQL Requests Made: 60 \n",
      "SPARQL Requests Total Time: 46.670934200286865 \n",
      "SPARQL Avg Time per Qn: 0.7778489033381144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: former champion Francisco Alarcon gave what award to Art Spiegelaman \n",
      "SPARQL Requests Made: 30 \n",
      "SPARQL Requests Total Time: 23.785815000534058 \n",
      "SPARQL Avg Time per Qn: 0.792860500017802\n",
      "[reRank_relations]: former champion Francisco Alarcon gave what award to Art Spiegelaman \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: located in the Central District, what is the county seat whose twin cities include Feodosiya \n",
      "SPARQL Requests Made: 181 \n",
      "SPARQL Requests Total Time: 140.7332227230072 \n",
      "SPARQL Avg Time per Qn: 0.7775316172541834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: former champion Francisco Alarcon gave what award to Art Spiegelaman \n",
      "SPARQL Requests Made: 30 \n",
      "SPARQL Requests Total Time: 23.089101791381836 \n",
      "SPARQL Avg Time per Qn: 0.7696367263793945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which borders of borders of Riverside have a begin date of 1984-0-0 \n",
      "SPARQL Requests Made: 165 \n",
      "SPARQL Requests Total Time: 127.56854963302612 \n",
      "SPARQL Avg Time per Qn: 0.7731427250486431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is {grant gotten} of {Hans Krebs} where {point in time} is {1966-0-0}  \n",
      "SPARQL Requests Made: 338 \n",
      "SPARQL Requests Total Time: 259.44201397895813 \n",
      "SPARQL Avg Time per Qn: 0.767579923014669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is a purpose of dying that begins with the letter p and can be located on a CT scan \n",
      "SPARQL Requests Made: 391 \n",
      "SPARQL Requests Total Time: 303.09335684776306 \n",
      "SPARQL Avg Time per Qn: 0.7751748256976038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which species is the ecia139-4120 protein found in \n",
      "SPARQL Requests Made: 450 \n",
      "SPARQL Requests Total Time: 349.4245536327362 \n",
      "SPARQL Avg Time per Qn: 0.7764990080727471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what product that contains paraffin wax has the lowest usage per capita \n",
      "SPARQL Requests Made: 450 \n",
      "SPARQL Requests Total Time: 350.71663451194763 \n",
      "SPARQL Avg Time per Qn: 0.7793702989154392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is a purpose of dying that begins with the letter p and can be located on a CT scan \n",
      "SPARQL Requests Made: 451 \n",
      "SPARQL Requests Total Time: 350.56281185150146 \n",
      "SPARQL Avg Time per Qn: 0.7773011349257238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is a purpose of dying that begins with the letter p and can be located on a CT scan \n",
      "SPARQL Requests Made: 83 \n",
      "SPARQL Requests Total Time: 64.82677674293518 \n",
      "SPARQL Avg Time per Qn: 0.7810455029269299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index error, no label found for\n",
      "wdt::P134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index error, no label found for\n",
      "wdt::P134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link batch time: 1437.2979004383087\n",
      "Anno batch time: 563.2361137866974\n",
      "Conv batch time: 0.0053026676177978516\n",
      "Pipeline iter 100\n",
      "Pipeline iter 101\n",
      "Pipeline iter 102\n",
      "Pipeline iter 103\n",
      "Pipeline iter 104\n",
      "Pipeline iter 105\n",
      "Pipeline iter 106\n",
      "Pipeline iter 107\n",
      "Pipeline iter 108\n",
      "Pipeline iter 109\n",
      "Pipeline iter 110\n",
      "Pipeline iter 111\n",
      "Pipeline iter 112\n",
      "Pipeline iter 113\n",
      "Pipeline iter 114\n",
      "Pipeline iter 115\n",
      "Pipeline iter 116\n",
      "Pipeline iter 117\n",
      "Pipeline iter 118\n",
      "Pipeline iter 119\n",
      "Pipeline iter 120\n",
      "Pipeline iter 121\n",
      "Pipeline iter 122\n",
      "Pipeline iter 123\n",
      "Pipeline iter 124\n",
      "Pipeline iter 125\n",
      "Pipeline iter 126\n",
      "Pipeline iter 127\n",
      "Pipeline iter 128\n",
      "Pipeline iter 129\n",
      "Pipeline iter 130\n",
      "Pipeline iter 131\n",
      "Pipeline iter 132\n",
      "Pipeline iter 133\n",
      "Pipeline iter 134\n",
      "Pipeline iter 135\n",
      "Pipeline iter 136\n",
      "Pipeline iter 137\n",
      "Pipeline iter 138\n",
      "Pipeline iter 139\n",
      "Pipeline iter 140\n",
      "Pipeline iter 141\n",
      "Pipeline iter 142\n",
      "Pipeline iter 143\n",
      "Pipeline iter 144\n",
      "Pipeline iter 145\n",
      "Pipeline iter 146\n",
      "Pipeline iter 147\n",
      "Pipeline iter 148\n",
      "Pipeline iter 149\n",
      "[Pipeline1]: Linking 99-149\n",
      "101 : ['Tell me each and every horse breed whose identify begins with the letter z']\n",
      "101 : ['The University of Florida is a member of which coalition?']\n",
      "101 : ['Give me the name of the brother in law of the writer of Quran.']\n",
      "101 : ['What is the New Zealand Gazetteer place id for Auckland?']\n",
      "101 : ['What does the portray Review Odalisque speak to which has DRTL backwards?']\n",
      "101 : ['Title an realm that contains the word british in its name']\n",
      "101 : ['Give me the instance of Antonio da Correggio, whose birthdate is 1489-8-1?']\n",
      "101 : ['Who was the instructor that administered Shigeno Yasutsugu?']\n",
      "101 : ['What is the SANDRE ID for Rhine?']\n",
      "101 : ['On what date did Kylie Minogue receive the Gold Logie Award for Most Popular Personality on Australian Television?']\n",
      "101 : ['What is the name of Alexander McQueens business?']\n",
      "101 : ['Let me know the Greek deity of kin of Zeus which contains the word poseidon in its name?']\n",
      "101 : ['Who organizes the arrange of Ultima III: Departure?']\n",
      "101 : ['Who was the lead performing artist for the motion picture Deadpool?']\n",
      "101 : ['Say the melodic related work highlighting the work of Sasha Grey.']\n",
      "101 : ['in 2011 John de Mol won which award?']\n",
      "101 : ['Is the entire richness rate of Algeria more noteworthy than 3.4284?']\n",
      "101 : ['When does the temperature and pressure of water hit the triple point stage?']\n",
      "101 : ['Let me know physical marvel whose title has the word surface in it.']\n",
      "101 : ['where does Vladimir putin reside?']\n",
      "101 : ['Which is the municipality of Belgium that has the headquarters location of European Union?']\n",
      "101 : ['Which is made from the goat meat having a common title as Household Goat?']\n",
      "101 : ['What is located on terrain feature of Multonmah Falls?']\n",
      "101 : ['Let me know ethnolect whose title has the word perkerdansk in it.']\n",
      "101 : ['What is the temperature and state of matter of water when it reaches the critical point?']\n",
      "101 : ['which is the point time for syria has populace as 8.08815e+06?']\n",
      "101 : ['Is Human communication, packaging and labeling involved with marketing?']\n",
      "101 : ['WHAT IS THE MAXIMUM FREQUENCY OF EVENT RACE']\n",
      "101 : ['WHICH IS THE AUSTRIAN MUNICIPALITY KEY OF  KLAGENFURT']\n",
      "101 : ['Tell me the self sustaining area of the Peoples Republic of China which consists of the phrase xinjiang in its name?']\n",
      "101 : ['What Velka Pardubicka has the lowest race time that was won by Peter Gehm?']\n",
      "101 : ['Who wrote the Watchmen, and what award were they given?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 : ['N / A N / A']\n",
      "103 : ['Name a book written in Esperanto']\n",
      "[reRank_relations]: say the melodic related work highlighting the work of Sasha Grey \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "[reRank_relations]: who was the lead performing artist for the motion picture Deadpool \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "104 : ['What is the general manager of Bernard Hinault?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: is Human communication, packaging and labeling involved with marketing \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "105 : ['What FSK 12 rated 3D film cost the most?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the SANDRE ID for Rhine \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 1.4556078910827637 \n",
      "SPARQL Avg Time per Qn: 1.4556078910827637\n",
      "106 : ['Daniel Dennett is interested in by how many people?']\n",
      "[reRank_relations]: what is located on terrain feature of Multonmah Falls \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 1.0566074848175049 \n",
      "SPARQL Avg Time per Qn: 1.0566074848175049\n",
      "107 : ['In the administrative territorial entity of Bristol, what significant event happened in 1996?']\n",
      "[reRank_relations]: wHICH IS THE AUSTRIAN MUNICIPALITY KEY OF  KLAGENFURT \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 1.1645641326904297 \n",
      "SPARQL Avg Time per Qn: 1.1645641326904297\n",
      "108 : ['Where does the river Rhine originate from?']\n",
      "[reRank_relations]: where does Vladimir putin reside \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 1.897026777267456 \n",
      "SPARQL Avg Time per Qn: 1.897026777267456\n",
      "[reRank_relations]: where does Vladimir putin reside \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "109 : ['What was Cate blanchett work Im Not There nominated for']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 : ['Tell me the tower that is depicted as Tower of Babel and includes the word babel in its name?']\n",
      "[reRank_relations]: give me the name of the brother in law of the writer of Quran \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 0.7361633777618408 \n",
      "SPARQL Avg Time per Qn: 0.7361633777618408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what was Cate blanchett work Im Not There nominated for \n",
      "SPARQL Requests Made: 1 \n",
      "SPARQL Requests Total Time: 0.7362236976623535 \n",
      "SPARQL Avg Time per Qn: 0.7362236976623535\n",
      "111 : ['Harold Macmillian of the 34th Parliament of the UK held which position starting from what date and then left for what reason?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: title an realm that contains the word british in its name \n",
      "SPARQL Requests Made: 4 \n",
      "SPARQL Requests Total Time: 3.0439116954803467 \n",
      "SPARQL Avg Time per Qn: 0.7609779238700867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the name of Alexander McQueens business \n",
      "SPARQL Requests Made: 4 \n",
      "SPARQL Requests Total Time: 5.511602401733398 \n",
      "SPARQL Avg Time per Qn: 1.3779006004333496\n",
      "[reRank_relations]: where does the river Rhine originate from \n",
      "SPARQL Requests Made: 4 \n",
      "SPARQL Requests Total Time: 3.178936243057251 \n",
      "SPARQL Avg Time per Qn: 0.7947340607643127\n",
      "112 : ['Is 700 the maximum wavelength of sensitivity of the human eye?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: in 2011 John de Mol won which award \n",
      "SPARQL Requests Made: 6 \n",
      "SPARQL Requests Total Time: 4.920626640319824 \n",
      "SPARQL Avg Time per Qn: 0.8201044400533041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 : ['Where was once the region of beginning of Hermann Heinrich Gossen, that has Q48460 such that 2--4355126?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: harold Macmillian of the 34th Parliament of the UK held which position starting from what date and then left for what reason \n",
      "SPARQL Requests Made: 5 \n",
      "SPARQL Requests Total Time: 3.753993034362793 \n",
      "SPARQL Avg Time per Qn: 0.7507986068725586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: give me the instance of Antonio da Correggio, whose birthdate is 1489-8-1 \n",
      "SPARQL Requests Made: 18 \n",
      "SPARQL Requests Total Time: 13.889828205108643 \n",
      "SPARQL Avg Time per Qn: 0.7716571225060357\n",
      "114 : ['Give me the person name who received nobel literature prize after Mo yan?']\n",
      "[reRank_relations]: in the administrative territorial entity of Bristol, what significant event happened in 1996 \n",
      "SPARQL Requests Made: 16 \n",
      "SPARQL Requests Total Time: 12.384342193603516 \n",
      "SPARQL Avg Time per Qn: 0.7740213871002197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is the municipality of Belgium that has the headquarters location of European Union \n",
      "SPARQL Requests Made: 20 \n",
      "SPARQL Requests Total Time: 15.63502836227417 \n",
      "SPARQL Avg Time per Qn: 0.7817514181137085\n",
      "115 : ['Which year was Eiji Toyoda awarded for his work in Order of Prince Henry?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which year was Eiji Toyoda awarded for his work in Order of Prince Henry \n",
      "SPARQL Requests Made: 2 \n",
      "SPARQL Requests Total Time: 1.4785325527191162 \n",
      "SPARQL Avg Time per Qn: 0.7392662763595581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: name a book written in Esperanto \n",
      "SPARQL Requests Made: 23 \n",
      "SPARQL Requests Total Time: 17.67067265510559 \n",
      "SPARQL Avg Time per Qn: 0.7682901154393735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which year was Eiji Toyoda awarded for his work in Order of Prince Henry \n",
      "SPARQL Requests Made: 6 \n",
      "SPARQL Requests Total Time: 4.5901408195495605 \n",
      "SPARQL Avg Time per Qn: 0.7650234699249268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which year was Eiji Toyoda awarded for his work in Order of Prince Henry \n",
      "SPARQL Requests Made: 2 \n",
      "SPARQL Requests Total Time: 1.506826639175415 \n",
      "SPARQL Avg Time per Qn: 0.7534133195877075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who was the instructor that administered Shigeno Yasutsugu \n",
      "SPARQL Requests Made: 30 \n",
      "SPARQL Requests Total Time: 23.103792190551758 \n",
      "SPARQL Avg Time per Qn: 0.7701264063517252\n",
      "[reRank_relations]: who was the instructor that administered Shigeno Yasutsugu \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "116 : ['What was Jimmy Wales start and end date during his employment at Bomis?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who wrote the Watchmen, and what award were they given \n",
      "SPARQL Requests Made: 36 \n",
      "SPARQL Requests Total Time: 27.841598510742188 \n",
      "SPARQL Avg Time per Qn: 0.7733777364095052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the New Zealand Gazetteer place id for Auckland \n",
      "SPARQL Requests Made: 37 \n",
      "SPARQL Requests Total Time: 29.490079402923584 \n",
      "SPARQL Avg Time per Qn: 0.7970291730519887\n",
      "[reRank_relations]: what is the New Zealand Gazetteer place id for Auckland \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "117 : ['Which is the author of afterword of Erich Fromm?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is the author of afterword of Erich Fromm \n",
      "SPARQL Requests Made: 2 \n",
      "SPARQL Requests Total Time: 1.4933533668518066 \n",
      "SPARQL Avg Time per Qn: 0.7466766834259033\n",
      "[reRank_relations]: which is the author of afterword of Erich Fromm \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "118 : ['Who are labored for Michelle Wolf and its source place of group/organisation is placed in New York City?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who are labored for Michelle Wolf and its source place of group/organisation is placed in New York City \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what Velka Pardubicka has the lowest race time that was won by Peter Gehm \n",
      "SPARQL Requests Made: 41 \n",
      "SPARQL Requests Total Time: 31.711262702941895 \n",
      "SPARQL Avg Time per Qn: 0.7734454317790705\n",
      "[reRank_relations]: what Velka Pardubicka has the lowest race time that was won by Peter Gehm \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n",
      "119 : ['What is the measuring unit that starts with the letter visus?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: name a book written in Esperanto \n",
      "SPARQL Requests Made: 23 \n",
      "SPARQL Requests Total Time: 17.852168321609497 \n",
      "SPARQL Avg Time per Qn: 0.7761812313743259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: tell me the self sustaining area of the Peoples Republic of China which consists of the phrase xinjiang in its name \n",
      "SPARQL Requests Made: 45 \n",
      "SPARQL Requests Total Time: 34.40845346450806 \n",
      "SPARQL Avg Time per Qn: 0.7646322992112902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the measuring unit that starts with the letter visus \n",
      "SPARQL Requests Made: 15 \n",
      "SPARQL Requests Total Time: 11.600711584091187 \n",
      "SPARQL Avg Time per Qn: 0.7733807722727458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the measuring unit that starts with the letter visus \n",
      "SPARQL Requests Made: 11 \n",
      "SPARQL Requests Total Time: 8.168355703353882 \n",
      "SPARQL Avg Time per Qn: 0.7425777912139893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who wrote the Watchmen, and what award were they given \n",
      "SPARQL Requests Made: 38 \n",
      "SPARQL Requests Total Time: 28.623723030090332 \n",
      "SPARQL Avg Time per Qn: 0.7532558692129034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: tell me the self sustaining area of the Peoples Republic of China which consists of the phrase xinjiang in its name \n",
      "SPARQL Requests Made: 31 \n",
      "SPARQL Requests Total Time: 24.236700296401978 \n",
      "SPARQL Avg Time per Qn: 0.7818290418194186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who organizes the arrange of Ultima III: Departure \n",
      "SPARQL Requests Made: 90 \n",
      "SPARQL Requests Total Time: 70.49067783355713 \n",
      "SPARQL Avg Time per Qn: 0.7832297537061903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: give me the person name who received nobel literature prize after Mo yan \n",
      "SPARQL Requests Made: 79 \n",
      "SPARQL Requests Total Time: 60.333104372024536 \n",
      "SPARQL Avg Time per Qn: 0.7637101819243612\n",
      "[reRank_relations]: give me the person name who received nobel literature prize after Mo yan \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who was the lead performing artist for the motion picture Deadpool \n",
      "SPARQL Requests Made: 109 \n",
      "SPARQL Requests Total Time: 84.2633330821991 \n",
      "SPARQL Avg Time per Qn: 0.7730581016715513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: title an realm that contains the word british in its name \n",
      "SPARQL Requests Made: 115 \n",
      "SPARQL Requests Total Time: 88.6581757068634 \n",
      "SPARQL Avg Time per Qn: 0.7709406583205514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on what date did Kylie Minogue receive the Gold Logie Award for Most Popular Personality on Australian Television \n",
      "SPARQL Requests Made: 120 \n",
      "SPARQL Requests Total Time: 92.72516179084778 \n",
      "SPARQL Avg Time per Qn: 0.7727096815903981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: on what date did Kylie Minogue receive the Gold Logie Award for Most Popular Personality on Australian Television \n",
      "SPARQL Requests Made: 5 \n",
      "SPARQL Requests Total Time: 3.8763580322265625 \n",
      "SPARQL Avg Time per Qn: 0.7752716064453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: let me know physical marvel whose title has the word surface in it \n",
      "SPARQL Requests Made: 147 \n",
      "SPARQL Requests Total Time: 115.08690905570984 \n",
      "SPARQL Avg Time per Qn: 0.7829041432361213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what was Jimmy Wales start and end date during his employment at Bomis \n",
      "SPARQL Requests Made: 132 \n",
      "SPARQL Requests Total Time: 100.95675420761108 \n",
      "SPARQL Avg Time per Qn: 0.7648238955122052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what was Jimmy Wales start and end date during his employment at Bomis \n",
      "SPARQL Requests Made: 3 \n",
      "SPARQL Requests Total Time: 2.2643754482269287 \n",
      "SPARQL Avg Time per Qn: 0.7547918160756429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what was Jimmy Wales start and end date during his employment at Bomis \n",
      "SPARQL Requests Made: 8 \n",
      "SPARQL Requests Total Time: 5.960026741027832 \n",
      "SPARQL Avg Time per Qn: 0.745003342628479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: say the melodic related work highlighting the work of Sasha Grey \n",
      "SPARQL Requests Made: 174 \n",
      "SPARQL Requests Total Time: 133.3651466369629 \n",
      "SPARQL Avg Time per Qn: 0.7664663599825453\n",
      "[reRank_relations]: say the melodic related work highlighting the work of Sasha Grey \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: give me the name of the brother in law of the writer of Quran \n",
      "SPARQL Requests Made: 180 \n",
      "SPARQL Requests Total Time: 138.38564920425415 \n",
      "SPARQL Avg Time per Qn: 0.7688091622458564\n",
      "[reRank_relations]: what is the temperature and state of matter of water when it reaches the critical point \n",
      "SPARQL Requests Made: 180 \n",
      "SPARQL Requests Total Time: 138.24914121627808 \n",
      "SPARQL Avg Time per Qn: 0.7680507845348782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what was Jimmy Wales start and end date during his employment at Bomis \n",
      "SPARQL Requests Made: 32 \n",
      "SPARQL Requests Total Time: 24.373950242996216 \n",
      "SPARQL Avg Time per Qn: 0.7616859450936317\n",
      "[reRank_relations]: what was Jimmy Wales start and end date during his employment at Bomis \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: harold Macmillian of the 34th Parliament of the UK held which position starting from what date and then left for what reason \n",
      "SPARQL Requests Made: 196 \n",
      "SPARQL Requests Total Time: 149.3656988143921 \n",
      "SPARQL Avg Time per Qn: 0.7620698919101637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: harold Macmillian of the 34th Parliament of the UK held which position starting from what date and then left for what reason \n",
      "SPARQL Requests Made: 23 \n",
      "SPARQL Requests Total Time: 17.726272344589233 \n",
      "SPARQL Avg Time per Qn: 0.7707074932430101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the general manager of Bernard Hinault \n",
      "SPARQL Requests Made: 225 \n",
      "SPARQL Requests Total Time: 171.39763927459717 \n",
      "SPARQL Avg Time per Qn: 0.7617672856648763\n",
      "[reRank_relations]: what is the general manager of Bernard Hinault \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: daniel Dennett is interested in by how many people \n",
      "SPARQL Requests Made: 227 \n",
      "SPARQL Requests Total Time: 177.9995517730713 \n",
      "SPARQL Avg Time per Qn: 0.7841389945950277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: tell me the tower that is depicted as Tower of Babel and includes the word babel in its name \n",
      "SPARQL Requests Made: 232 \n",
      "SPARQL Requests Total Time: 178.5637547969818 \n",
      "SPARQL Avg Time per Qn: 0.7696713568835423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: harold Macmillian of the 34th Parliament of the UK held which position starting from what date and then left for what reason \n",
      "SPARQL Requests Made: 19 \n",
      "SPARQL Requests Total Time: 14.929994106292725 \n",
      "SPARQL Avg Time per Qn: 0.7857891634890908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: in the administrative territorial entity of Bristol, what significant event happened in 1996 \n",
      "SPARQL Requests Made: 226 \n",
      "SPARQL Requests Total Time: 174.92453455924988 \n",
      "SPARQL Avg Time per Qn: 0.7740023653064154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: let me know ethnolect whose title has the word perkerdansk in it \n",
      "SPARQL Requests Made: 246 \n",
      "SPARQL Requests Total Time: 190.56475257873535 \n",
      "SPARQL Avg Time per Qn: 0.7746534657672168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what does the portray Review Odalisque speak to which has DRTL backwards \n",
      "SPARQL Requests Made: 243 \n",
      "SPARQL Requests Total Time: 188.91267037391663 \n",
      "SPARQL Avg Time per Qn: 0.77741839660048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the name of Alexander McQueens business \n",
      "SPARQL Requests Made: 240 \n",
      "SPARQL Requests Total Time: 184.47193670272827 \n",
      "SPARQL Avg Time per Qn: 0.7686330695947011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: harold Macmillian of the 34th Parliament of the UK held which position starting from what date and then left for what reason \n",
      "SPARQL Requests Made: 23 \n",
      "SPARQL Requests Total Time: 17.49855089187622 \n",
      "SPARQL Avg Time per Qn: 0.7608065605163574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occured when querying SPARQL, trying again in 10 seconds\n",
      "<urlopen error [Errno -3] Temporary failure in name resolution>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: let me know the Greek deity of kin of Zeus which contains the word poseidon in its name \n",
      "SPARQL Requests Made: 274 \n",
      "SPARQL Requests Total Time: 212.31252026557922 \n",
      "SPARQL Avg Time per Qn: 0.7748632126480993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: who are labored for Michelle Wolf and its source place of group/organisation is placed in New York City \n",
      "SPARQL Requests Made: 241 \n",
      "SPARQL Requests Total Time: 188.45342183113098 \n",
      "SPARQL Avg Time per Qn: 0.7819644059383029\n",
      "[reRank_relations]: who are labored for Michelle Wolf and its source place of group/organisation is placed in New York City \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the measuring unit that starts with the letter visus \n",
      "SPARQL Requests Made: 225 \n",
      "SPARQL Requests Total Time: 175.08400988578796 \n",
      "SPARQL Avg Time per Qn: 0.7781511550479465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: harold Macmillian of the 34th Parliament of the UK held which position starting from what date and then left for what reason \n",
      "SPARQL Requests Made: 44 \n",
      "SPARQL Requests Total Time: 34.62201285362244 \n",
      "SPARQL Avg Time per Qn: 0.7868639284914191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which year was Eiji Toyoda awarded for his work in Order of Prince Henry \n",
      "SPARQL Requests Made: 300 \n",
      "SPARQL Requests Total Time: 231.45698499679565 \n",
      "SPARQL Avg Time per Qn: 0.7715232833226522\n",
      "[reRank_relations]: which year was Eiji Toyoda awarded for his work in Order of Prince Henry \n",
      "SPARQL Requests Made: 0 \n",
      "SPARQL Requests Total Time: 0 \n",
      "SPARQL Avg Time per Qn: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: tell me the self sustaining area of the Peoples Republic of China which consists of the phrase xinjiang in its name \n",
      "SPARQL Requests Made: 235 \n",
      "SPARQL Requests Total Time: 208.61271381378174 \n",
      "SPARQL Avg Time per Qn: 0.8877136758033265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: let me know the Greek deity of kin of Zeus which contains the word poseidon in its name \n",
      "SPARQL Requests Made: 64 \n",
      "SPARQL Requests Total Time: 51.735069036483765 \n",
      "SPARQL Avg Time per Qn: 0.8083604536950588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: let me know the Greek deity of kin of Zeus which contains the word poseidon in its name \n",
      "SPARQL Requests Made: 17 \n",
      "SPARQL Requests Total Time: 12.882360458374023 \n",
      "SPARQL Avg Time per Qn: 0.757785909316119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what does the portray Review Odalisque speak to which has DRTL backwards \n",
      "SPARQL Requests Made: 108 \n",
      "SPARQL Requests Total Time: 84.4263985157013 \n",
      "SPARQL Avg Time per Qn: 0.7817259121824194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: tell me the tower that is depicted as Tower of Babel and includes the word babel in its name \n",
      "SPARQL Requests Made: 149 \n",
      "SPARQL Requests Total Time: 118.1272840499878 \n",
      "SPARQL Avg Time per Qn: 0.7928005640938778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: when does the temperature and pressure of water hit the triple point stage \n",
      "SPARQL Requests Made: 390 \n",
      "SPARQL Requests Total Time: 303.2327456474304 \n",
      "SPARQL Avg Time per Qn: 0.777519860634437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what does the portray Review Odalisque speak to which has DRTL backwards \n",
      "SPARQL Requests Made: 45 \n",
      "SPARQL Requests Total Time: 34.94425129890442 \n",
      "SPARQL Avg Time per Qn: 0.7765389177534315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: in 2011 John de Mol won which award \n",
      "SPARQL Requests Made: 420 \n",
      "SPARQL Requests Total Time: 328.2778043746948 \n",
      "SPARQL Avg Time per Qn: 0.7816138199397495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: where was once the region of beginning of Hermann Heinrich Gossen, that has Q48460 such that 2--4355126 \n",
      "SPARQL Requests Made: 450 \n",
      "SPARQL Requests Total Time: 351.0114848613739 \n",
      "SPARQL Avg Time per Qn: 0.7800255219141642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the temperature and state of matter of water when it reaches the critical point \n",
      "SPARQL Requests Made: 300 \n",
      "SPARQL Requests Total Time: 234.90506672859192 \n",
      "SPARQL Avg Time per Qn: 0.7830168890953064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: where was once the region of beginning of Hermann Heinrich Gossen, that has Q48460 such that 2--4355126 \n",
      "SPARQL Requests Made: 30 \n",
      "SPARQL Requests Total Time: 23.20270872116089 \n",
      "SPARQL Avg Time per Qn: 0.7734236240386962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: tell me each and every horse breed whose identify begins with the letter z \n",
      "SPARQL Requests Made: 496 \n",
      "SPARQL Requests Total Time: 385.0925419330597 \n",
      "SPARQL Avg Time per Qn: 0.7763962538972977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: where was once the region of beginning of Hermann Heinrich Gossen, that has Q48460 such that 2--4355126 \n",
      "SPARQL Requests Made: 30 \n",
      "SPARQL Requests Total Time: 23.359612941741943 \n",
      "SPARQL Avg Time per Qn: 0.7786537647247315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: in 2011 John de Mol won which award \n",
      "SPARQL Requests Made: 136 \n",
      "SPARQL Requests Total Time: 105.1626844406128 \n",
      "SPARQL Avg Time per Qn: 0.7732550326515647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: wHAT IS THE MAXIMUM FREQUENCY OF EVENT RACE \n",
      "SPARQL Requests Made: 633 \n",
      "SPARQL Requests Total Time: 490.2158272266388 \n",
      "SPARQL Avg Time per Qn: 0.7744325864559854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: wHAT IS THE MAXIMUM FREQUENCY OF EVENT RACE \n",
      "SPARQL Requests Made: 35 \n",
      "SPARQL Requests Total Time: 27.465616703033447 \n",
      "SPARQL Avg Time per Qn: 0.7847319058009556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is made from the goat meat having a common title as Household Goat \n",
      "SPARQL Requests Made: 675 \n",
      "SPARQL Requests Total Time: 529.1140244007111 \n",
      "SPARQL Avg Time per Qn: 0.7838726287417942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: which is made from the goat meat having a common title as Household Goat \n",
      "SPARQL Requests Made: 9 \n",
      "SPARQL Requests Total Time: 9.15455412864685 \n",
      "SPARQL Avg Time per Qn: 1.017172680960761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: when does the temperature and pressure of water hit the triple point stage \n",
      "SPARQL Requests Made: 300 \n",
      "SPARQL Requests Total Time: 232.57140612602234 \n",
      "SPARQL Avg Time per Qn: 0.7752380204200745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: when does the temperature and pressure of water hit the triple point stage \n",
      "SPARQL Requests Made: 180 \n",
      "SPARQL Requests Total Time: 141.2850158214569 \n",
      "SPARQL Avg Time per Qn: 0.7849167545636495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what is the temperature and state of matter of water when it reaches the critical point \n",
      "SPARQL Requests Made: 411 \n",
      "SPARQL Requests Total Time: 319.69640350341797 \n",
      "SPARQL Avg Time per Qn: 0.7778501301786326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what FSK 12 rated 3D film cost the most \n",
      "SPARQL Requests Made: 1125 \n",
      "SPARQL Requests Total Time: 870.5447239875793 \n",
      "SPARQL Avg Time per Qn: 0.7738175324334039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: what FSK 12 rated 3D film cost the most \n",
      "SPARQL Requests Made: 443 \n",
      "SPARQL Requests Total Time: 343.31296396255493 \n",
      "SPARQL Avg Time per Qn: 0.7749728306152481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRank_relations]: wHAT IS THE MAXIMUM FREQUENCY OF EVENT RACE \n",
      "SPARQL Requests Made: 1041 \n",
      "SPARQL Requests Total Time: 807.1136529445648 \n",
      "SPARQL Avg Time per Qn: 0.7753253150284004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index error, no label found for\n",
      "wd::Q3521547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index error, no label found for\n",
      "wdt::P1432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index error, no label found for\n",
      "wdt::P134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index error, no label found for\n",
      "wdt::P134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link batch time: 2650.0686898231506\n",
      "Anno batch time: 716.0920572280884\n",
      "Conv batch time: 0.006600141525268555\n",
      "Pipeline iter 150\n",
      "Pipeline iter 151\n",
      "Pipeline iter 152\n",
      "Pipeline iter 153\n",
      "Pipeline iter 154\n",
      "Pipeline iter 155\n",
      "Pipeline iter 156\n",
      "Pipeline iter 157\n",
      "Pipeline iter 158\n",
      "Pipeline iter 159\n",
      "Pipeline iter 160\n",
      "Pipeline iter 161\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m answer \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparql_wikidata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     linked, annotated, converted = pipe(question, answer)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     print(e)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# responses.append([linked, annotated, converted])\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     18\u001b[0m     batch_qns\u001b[38;5;241m.\u001b[39mappend(question)\n\u001b[1;32m     19\u001b[0m     batch_ans\u001b[38;5;241m.\u001b[39mappend(answer)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "batch_qns = []\n",
    "batch_ans = []\n",
    "truncated_data = data_dict\n",
    "total_len = len(truncated_data)\n",
    "last = 0\n",
    "for i, data in enumerate(truncated_data):\n",
    "    print(\"Pipeline iter\", i)\n",
    "    question = data[\"new_question\"]\n",
    "    answer = data[\"sparql_wikidata\"]\n",
    "    # try:\n",
    "    #     linked, annotated, converted = pipe(question, answer)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     continue\n",
    "    # responses.append([linked, annotated, converted])\n",
    "    if len(question) >= 2:\n",
    "        batch_qns.append(question)\n",
    "        batch_ans.append(answer)\n",
    "    if ((i + 1) % 50) == 0 or i == total_len - 1:\n",
    "        print(\"[Pipeline1]:\", f\"Linking {last}-{i}\")\n",
    "        try:\n",
    "            for linked, annotated, converted in pipe_batch(batch_qns, batch_ans):\n",
    "                responses.append([linked, annotated, converted])\n",
    "            batch_qns = []\n",
    "            batch_ans = []\n",
    "            last = i\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            # print(e)\n",
    "            # continue\n",
    "        with open(f\"../t5-for-sparql/falcon_links/2/link_{i}.json\", \"w\") as f:\n",
    "            json.dump(responses, f, indent=2, separators=(',',':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167645e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# qns = ['What is the operating income for Qantas?', 'What is Mary Lou Rettons International Olympic Committee athlete ID.']\n",
    "# l = linker.link_batch(qns)\n",
    "# print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51573f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"home.json\", \"w\") as f:\n",
    "  json.dump(responses, f, indent=2 ,separators=(',', ': '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7358.272019,
   "end_time": "2023-07-12T17:04:23.653046",
   "environment_variables": {},
   "exception": true,
   "input_path": "pipeline1.ipynb",
   "output_path": "pipeline1-home.papermill.ipynb",
   "parameters": {},
   "start_time": "2023-07-12T15:01:45.381027",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}